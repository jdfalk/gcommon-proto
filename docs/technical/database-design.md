# Database Module Technical Design

## Overview

The database module provides a unified interface for interacting with different database backends, including PostgreSQL, CockroachDB, SQLite3, and Pebble. This design document outlines the architecture, interfaces, and implementation details for the database module.

## Goals

- Provide a consistent API across different database backends
- Abstract connection management and pooling
- Support migrations
- Handle transactions seamlessly
- Support both SQL and NoSQL operations where possible
- Make it easy to switch between database backends
- Ensure proper resource management and cleanup

## Architecture

### Core Components

```text
                 +--------------+
                 |   Provider   |
                 +------+-------+
                        |
            +-----------+-----------+
            |           |           |
    +-------+---+ +-----+-----+ +---+-------+
    |  SQL DB   | | KV Store  | | Migration |
    +-----------+ +-----------+ +-----------+
            |           |           |
    +-------+---+ +-----+-----+ +---+-------+
    | Connection | | Transaction| |  Query   |
    |    Pool    | |  Manager   | | Builder  |
    +-----------+ +-----------+ +-----------+
```

### Component Design

#### Provider Interface

The core of the module is the `Provider` interface, which defines the common operations across all database backends. This interface is implemented by each database driver.

#### Database Drivers

Each supported database has a dedicated driver package:

- `postgres`: PostgreSQL implementation
- `cockroachdb`: CockroachDB implementation
- `sqlite`: SQLite3 implementation (default)
- `pebble`: Pebble implementation (key-value store)

#### Factory

A factory function creates the appropriate provider based on the configuration, making it easy to switch between database backends without changing code.

#### Connection Pool

Each provider manages a connection pool appropriate for the underlying database, ensuring efficient resource utilization.

#### Migration System

The migration system supports SQL migrations for SQL databases and custom migrations for NoSQL databases, ensuring database schema is properly versioned and updated.

#### Query Builder

A query builder allows for constructing SQL queries in a database-agnostic way, promoting code reusability across different SQL dialects.

## Interface Design

### Provider

```go
// Provider represents a database provider.
type Provider interface {
    // Connect establishes a connection to the database.
    Connect(ctx context.Context) error

    // Close closes the database connection.
    Close(ctx context.Context) error

    // Ping checks if the database is reachable.
    Ping(ctx context.Context) error

    // Transaction starts a new transaction.
    Transaction(ctx context.Context) (Transaction, error)

    // Migrate runs pending migrations.
    Migrate(ctx context.Context, migrationsPath string) error

    // Query executes a query and returns rows.
    Query(ctx context.Context, query string, args ...interface{}) (Rows, error)

    // Exec executes a query without returning rows.
    Exec(ctx context.Context, query string, args ...interface{}) (Result, error)

    // Prepare creates a prepared statement for later queries or executions.
    Prepare(ctx context.Context, query string) (Statement, error)
}
```

### Transaction

```go
// Transaction represents a database transaction.
type Transaction interface {
    // Commit commits the transaction.
    Commit(ctx context.Context) error

    // Rollback aborts the transaction.
    Rollback(ctx context.Context) error

    // Query executes a query within the transaction.
    Query(ctx context.Context, query string, args ...interface{}) (Rows, error)

    // Exec executes a query within the transaction.
    Exec(ctx context.Context, query string, args ...interface{}) (Result, error)

    // Prepare creates a prepared statement for later queries or executions within the transaction.
    Prepare(ctx context.Context, query string) (Statement, error)
}
```

### Rows

```go
// Rows represents the result of a query.
type Rows interface {
    // Next moves the cursor to the next row.
    Next() bool

    // Scan copies the columns in the current row into the values pointed to by dest.
    Scan(dest ...interface{}) error

    // Close closes the rows iterator.
    Close() error

    // Columns returns the column names.
    Columns() ([]string, error)

    // ColumnTypes returns the column types.
    ColumnTypes() ([]ColumnType, error)

    // Err returns the error, if any, that was encountered during iteration.
    Err() error
}
```

### Result

```go
// Result represents the result of an exec query.
type Result interface {
    // LastInsertId returns the integer generated by the database in response to a command.
    LastInsertId() (int64, error)

    // RowsAffected returns the number of rows affected by the query.
    RowsAffected() (int64, error)
}
```

### Statement

```go
// Statement represents a prepared statement.
type Statement interface {
    // Query executes a query that returns rows.
    Query(ctx context.Context, args ...interface{}) (Rows, error)

    // Exec executes a query that doesn't return rows.
    Exec(ctx context.Context, args ...interface{}) (Result, error)

    // Close closes the statement.
    Close(ctx context.Context) error
}
```

## Configuration

### Config Structure

```go
// Config represents the database configuration.
type Config struct {
    // Driver specifies the database driver to use.
    // Supported values: "postgres", "cockroachdb", "sqlite", "pebble"
    Driver string

    // ConnectionString is the connection string for the database.
    ConnectionString string

    // Host is the database server host.
    Host string

    // Port is the database server port.
    Port int

    // Username is the database user.
    Username string

    // Password is the database password.
    Password string

    // Database is the database name.
    Database string

    // SSLMode specifies whether to use SSL.
    SSLMode string

    // MaxOpenConnections limits the number of open connections.
    MaxOpenConnections int

    // MaxIdleConnections limits the number of idle connections.
    MaxIdleConnections int

    // ConnectionMaxLifetime limits the maximum lifetime of a connection.
    ConnectionMaxLifetime time.Duration

    // QueryTimeout sets the timeout for queries.
    QueryTimeout time.Duration

    // MigrationsTable is the name of the migrations table.
    MigrationsTable string

    // Additional driver-specific options
    Options map[string]interface{}
}
```

## Implementation Details

### SQLite Implementation

The SQLite implementation uses `go-sqlite3` as the underlying driver and provides a lightweight database solution suitable for development, testing, or small applications.

### PostgreSQL Implementation

The PostgreSQL implementation uses `pgx` as the underlying driver, which provides better performance than the standard `lib/pq` driver.

### CockroachDB Implementation

The CockroachDB implementation extends the PostgreSQL implementation with CockroachDB-specific features and optimizations.

### Pebble Implementation

The Pebble implementation provides a key-value store interface using CockroachDB's Pebble storage engine, suitable for applications requiring high-performance, embedded storage.

### Connection Management

Each provider implementation manages its connection pool according to best practices for the specific database type.

### Error Handling

Errors are wrapped with appropriate context to provide meaningful error messages to callers. The error types provide methods to check for specific error conditions (like unique constraint violations).

### Metrics and Logging

The database module integrates with the metrics and logging modules to provide detailed monitoring and debugging information.

## Migration System

The migration system supports:

- SQL-based migrations
- Code-based migrations
- Version tracking
- Up and down migrations
- Migration history

Migrations can be applied automatically on startup or manually triggered.

## Usage Examples

### Basic Connection

```go
config := db.Config{
    Driver:   "postgres",
    Host:     "localhost",
    Port:     5432,
    Username: "user",
    Password: "password",
    Database: "mydb",
}

provider, err := db.New(config)
if err != nil {
    log.Fatal(err)
}

ctx := context.Background()
if err := provider.Connect(ctx); err != nil {
    log.Fatal(err)
}
defer provider.Close(ctx)
```

### Executing Queries

```go
rows, err := provider.Query(ctx, "SELECT id, name FROM users WHERE age > $1", 18)
if err != nil {
    log.Fatal(err)
}
defer rows.Close()

for rows.Next() {
    var id int
    var name string
    if err := rows.Scan(&id, &name); err != nil {
        log.Fatal(err)
    }
    fmt.Printf("ID: %d, Name: %s\n", id, name)
}

if err := rows.Err(); err != nil {
    log.Fatal(err)
}
```

### Transactions

```go
tx, err := provider.Transaction(ctx)
if err != nil {
    log.Fatal(err)
}

_, err = tx.Exec(ctx, "UPDATE users SET balance = balance - $1 WHERE id = $2", 100, 1)
if err != nil {
    tx.Rollback(ctx)
    log.Fatal(err)
}

_, err = tx.Exec(ctx, "UPDATE users SET balance = balance + $1 WHERE id = $2", 100, 2)
if err != nil {
    tx.Rollback(ctx)
    log.Fatal(err)
}

if err := tx.Commit(ctx); err != nil {
    log.Fatal(err)
}
```

### Using Prepared Statements

```go
stmt, err := provider.Prepare(ctx, "INSERT INTO users(name, email) VALUES($1, $2)")
if err != nil {
    log.Fatal(err)
}
defer stmt.Close(ctx)

for _, user := range users {
    _, err := stmt.Exec(ctx, user.Name, user.Email)
    if err != nil {
        log.Fatal(err)
    }
}
```

## Testing Strategy

- Unit tests for each provider implementation
- Integration tests with actual database instances
- Benchmarks for performance-critical operations
- Mock implementations for higher-level tests

## Security Considerations

- Connection strings and credentials are handled securely
- Prepared statements are used to prevent SQL injection
- TLS/SSL support for secure connections
- Password encryption for storage

## Performance Considerations

- Connection pooling optimized for each database type
- Efficient query execution strategies
- Prepared statements for repeated queries
- Query timeout management
- Configurable connection lifecycle
